{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fbd08487",
   "metadata": {},
   "source": [
    "# <center><font color='blue'>SkimLit</center></font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9abd523",
   "metadata": {},
   "source": [
    "## Table of contents\n",
    "- [1 - Objectives](#1)\n",
    "- [2 - Setup](#2)\n",
    "- [3 - Data Loading and Visualization](#3)\n",
    "- [4 - Data pre-processing](#4)\n",
    "    - [4.1. - Formatting our data](#4.1)\n",
    "    - [4.2. - More visualization](#4.2)\n",
    "    - [4.3. - Categorical data](#4.3)\n",
    "    - [4.4. - Pre-processing for NLP](#4.4)\n",
    "    - [4.5. - Creating tensorflow datasets](#4.5)\n",
    "- [5 - Models](#5)\n",
    "    - [5.1. - Embedding layer](#5.1)\n",
    "    - [5.2. - Trying different models](#5.2)\n",
    "        - [5.2.1 - Model 1](#5.2.1)\n",
    "        - [5.2.2 - Model 2](#5.2.2)\n",
    "        - [5.2.3 - Model 3](#5.2.3)\n",
    "        - [5.2.4 - Model 4](#5.2.4)\n",
    "        - [5.2.5 - Model 5](#5.2.5)\n",
    "- [6 - Compare results](#6)\n",
    "- [7 - Conclusions](#7)\n",
    "- [8 - References](#8)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a14cea80",
   "metadata": {},
   "source": [
    "<a name=\"1\"></a>\n",
    "## <b> <font color='blue'> 1. Objectives </font> </b>\n",
    "Build an NLP model to make reading medical abstracts easier.\n",
    "\n",
    "The paper we're replicating (the source of the dataset that we'll be using) is available here: https://arxiv.org/abs/1710.06071\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d22725ba",
   "metadata": {},
   "source": [
    "<a name=\"2\"></a>\n",
    "## <b> <font color='blue'> 2. Setup </font> </b>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2f10078",
   "metadata": {},
   "source": [
    "What we are looking for is to associate a specific label (objective, background, result...) with a given sentence (composed of many words), so it is a many-to-one problem.\n",
    "\n",
    "### Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ffa9711c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# que no se impriman info y warnings\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2' \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e9ab0e77",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-26 18:56:04.425535: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-07-26 18:56:04.425568: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-07-26 18:56:04.426684: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import random\n",
    "import re\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import string\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, callbacks, models, Sequential, losses\n",
    "from tensorflow import keras\n",
    "\n",
    "from utils import plot_hist\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fc0455e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# random seed\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fff93be",
   "metadata": {},
   "source": [
    "<a name=\"3\"></a>\n",
    "## <b> <font color='blue'> 3.  Data Loading and Visualization </font> </b>\n",
    "\n",
    "Let's download the data.\n",
    "\n",
    "We can do so from the authors GitHub: https://github.com/Franck-Dernoncourt/pubmed-rct "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "14ffb77d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fatal: la ruta de destino 'pubmed-rct' ya existe y no es un directorio vac√≠o.\n",
      "PubMed_200k_RCT\n",
      "PubMed_200k_RCT_numbers_replaced_with_at_sign\n",
      "PubMed_20k_RCT\n",
      "PubMed_20k_RCT_numbers_replaced_with_at_sign\n",
      "README.md\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/Franck-Dernoncourt/pubmed-rct\n",
    "!dir pubmed-rct #ls"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30787a52",
   "metadata": {},
   "source": [
    "There are 2 datasets, one with 20000 examples (usefull for the initial tests) and another one with 200k examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d9223d33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dev.txt  test.txt  train.txt\r\n"
     ]
    }
   ],
   "source": [
    "# Check what files are in the PubMed_20K dataset\n",
    "!ls pubmed-rct/PubMed_20k_RCT_numbers_replaced_with_at_sign"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "742bb385",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start our experiments using the 20k dataset with numbers replaced by \"@\" sign\n",
    "data_dir = \"pubmed-rct/PubMed_20k_RCT_numbers_replaced_with_at_sign/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "882f169b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['pubmed-rct/PubMed_20k_RCT_numbers_replaced_with_at_sign/train.txt',\n",
       " 'pubmed-rct/PubMed_20k_RCT_numbers_replaced_with_at_sign/dev.txt',\n",
       " 'pubmed-rct/PubMed_20k_RCT_numbers_replaced_with_at_sign/test.txt']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check all of the filenames in the target directory\n",
    "filenames = [data_dir + filename for filename in os.listdir(data_dir)]\n",
    "filenames"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "470e43b1",
   "metadata": {},
   "source": [
    "So with that in mind, let's write a function to read in all of the lines of a target text file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d3d60e6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create function to read the lines of a document\n",
    "def get_lines(filename):\n",
    "  \"\"\"\n",
    "  Reads filename (a text filename) and returns the lines of text as a list.\n",
    "\n",
    "  Args:\n",
    "    filename: a string containing the target filepath.\n",
    "\n",
    "  Returns:\n",
    "    A list of strings with one string per line from the target filename.\n",
    "  \"\"\"\n",
    "  with open(filename, \"r\") as f:\n",
    "    return f.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dd5532a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['###24293578\\n',\n",
       " 'OBJECTIVE\\tTo investigate the efficacy of @ weeks of daily low-dose oral prednisolone in improving pain , mobility , and systemic low-grade inflammation in the short term and whether the effect would be sustained at @ weeks in older adults with moderate to severe knee osteoarthritis ( OA ) .\\n',\n",
       " 'METHODS\\tA total of @ patients with primary knee OA were randomized @:@ ; @ received @ mg/day of prednisolone and @ received placebo for @ weeks .\\n',\n",
       " 'METHODS\\tOutcome measures included pain reduction and improvement in function scores and systemic inflammation markers .\\n',\n",
       " 'METHODS\\tPain was assessed using the visual analog pain scale ( @-@ mm ) .\\n',\n",
       " 'METHODS\\tSecondary outcome measures included the Western Ontario and McMaster Universities Osteoarthritis Index scores , patient global assessment ( PGA ) of the severity of knee OA , and @-min walk distance ( @MWD ) .\\n',\n",
       " 'METHODS\\tSerum levels of interleukin @ ( IL-@ ) , IL-@ , tumor necrosis factor ( TNF ) - , and high-sensitivity C-reactive protein ( hsCRP ) were measured .\\n',\n",
       " 'RESULTS\\tThere was a clinically relevant reduction in the intervention group compared to the placebo group for knee pain , physical function , PGA , and @MWD at @ weeks .\\n',\n",
       " 'RESULTS\\tThe mean difference between treatment arms ( @ % CI ) was @ ( @-@ @ ) , p < @ ; @ ( @-@ @ ) , p < @ ; @ ( @-@ @ ) , p < @ ; and @ ( @-@ @ ) , p < @ , respectively .\\n',\n",
       " 'RESULTS\\tFurther , there was a clinically relevant reduction in the serum levels of IL-@ , IL-@ , TNF - , and hsCRP at @ weeks in the intervention group when compared to the placebo group .\\n',\n",
       " 'RESULTS\\tThese differences remained significant at @ weeks .\\n',\n",
       " 'RESULTS\\tThe Outcome Measures in Rheumatology Clinical Trials-Osteoarthritis Research Society International responder rate was @ % in the intervention group and @ % in the placebo group ( p < @ ) .\\n',\n",
       " 'CONCLUSIONS\\tLow-dose oral prednisolone had both a short-term and a longer sustained effect resulting in less knee pain , better physical function , and attenuation of systemic inflammation in older patients with knee OA ( ClinicalTrials.gov identifier NCT@ ) .\\n',\n",
       " '\\n',\n",
       " '###24854809\\n']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's read in the training lines and see some of them\n",
    "train_lines = get_lines(data_dir+\"train.txt\") # read the lines with the training file\n",
    "\n",
    "to_show = 15\n",
    "train_lines[:to_show]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc57d4e9",
   "metadata": {},
   "source": [
    "We see that the abstracts:\n",
    "\n",
    "- Start with \"###\n",
    "- Followed by an ID and a newline character (\\n)\n",
    "- Each sentence has a label (for example RESULTS, METHODS..) (starting with the label and then \\t)\n",
    "- The end is indicated by a newline charecter (\\n).\n",
    "\n",
    "<br>\n",
    "We need a function to separate the text from the labels and the different abstracts."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a93d75e7",
   "metadata": {},
   "source": [
    "<a name=\"4\"></a>\n",
    "## <b> <font color='blue'> 4.  Data pre-processing </font> </b>\n",
    "\n",
    "\n",
    "<a name=\"4.1\"></a>\n",
    "### <b> <font color='#1F618D'> 4.1. Formatting our data </font> </b>\n",
    "\n",
    "We want that our data looks like this:\n",
    "\n",
    "```\n",
    "[{'line_number': 0,\n",
    "   'target': 'BACKGROUND',\n",
    "   'text': \"Emotional eating is associated with overeating and the development of obesity .\\n\"\n",
    "   'total_lines': 11},\n",
    "   ...]\n",
    "```\n",
    "\n",
    "total lines it's the number of lines in the abstract (that we want to classify sequentially)\n",
    "\n",
    "Let's write a function which turns each of our datasets into the above format so we can continue to prepare our data for modelling.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6f9c545c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text_with_line_numbers(filename):\n",
    "  \"\"\"\n",
    "  Returns a list of dictionaries of abstract line data.\n",
    "\n",
    "  Takes in filename, reads it contents and sorts through each line,\n",
    "  extracting things like the target label, the text of the sentnece,\n",
    "  how many sentences are in the current abstract and what sentence\n",
    "  number the target line is.\n",
    "  \"\"\"\n",
    "  input_lines = get_lines(filename) # get all lines from filename\n",
    "  abstract_lines = \"\" # create an empty abstract\n",
    "  abstract_samples = [] # create an empty list of abstracts\n",
    "\n",
    "  # Loop through each line in the target file\n",
    "  for line in input_lines:\n",
    "    if line.startswith(\"###\"): # check to see if the is an ID line\n",
    "      abstract_id = line\n",
    "      abstract_lines = \"\" # reset the abstract string if the line is an ID line\n",
    "\n",
    "    elif line.isspace(): # check to see if line is a new line\n",
    "      abstract_line_split = abstract_lines.splitlines() # split abstract into separate lines\n",
    "\n",
    "      # Iterate through each line in a single abstract and count them at the same time\n",
    "      for abstract_line_number, abstract_line in enumerate(abstract_line_split):\n",
    "        line_data = {} # create an empty dictionary for each line\n",
    "        target_text_split = abstract_line.split(\"\\t\") # split target label from text \n",
    "        line_data[\"target\"] = target_text_split[0] # get target label\n",
    "        line_data[\"text\"] = target_text_split[1].lower() # get target text and lower it\n",
    "        line_data[\"line_number\"] = abstract_line_number # what number line does the line appear in the abstract?\n",
    "        line_data[\"total_lines\"] = len(abstract_line_split) - 1 # how many total lines are there in the target abstract? (start from 0)\n",
    "        abstract_samples.append(line_data) # add line data to abstract samples list\n",
    "\n",
    "    else: # if the above conditions aren't fulfilled, the line contains a labelled sentence\n",
    "      abstract_lines += line\n",
    "  \n",
    "  return abstract_samples\n",
    "\n",
    "          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f4548271",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "180040 30212 30135\n"
     ]
    }
   ],
   "source": [
    "# Get data from file and preprocess it\n",
    "train_samples = preprocess_text_with_line_numbers(data_dir + \"train.txt\")\n",
    "val_samples = preprocess_text_with_line_numbers(data_dir + \"dev.txt\") # dev is another name for validation dataset\n",
    "test_samples = preprocess_text_with_line_numbers(data_dir + \"test.txt\")\n",
    "\n",
    "print(len(train_samples), len(val_samples), len(test_samples))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ccf54a8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'target': 'OBJECTIVE',\n",
       "  'text': 'to investigate the efficacy of @ weeks of daily low-dose oral prednisolone in improving pain , mobility , and systemic low-grade inflammation in the short term and whether the effect would be sustained at @ weeks in older adults with moderate to severe knee osteoarthritis ( oa ) .',\n",
       "  'line_number': 0,\n",
       "  'total_lines': 11},\n",
       " {'target': 'METHODS',\n",
       "  'text': 'a total of @ patients with primary knee oa were randomized @:@ ; @ received @ mg/day of prednisolone and @ received placebo for @ weeks .',\n",
       "  'line_number': 1,\n",
       "  'total_lines': 11},\n",
       " {'target': 'METHODS',\n",
       "  'text': 'outcome measures included pain reduction and improvement in function scores and systemic inflammation markers .',\n",
       "  'line_number': 2,\n",
       "  'total_lines': 11},\n",
       " {'target': 'METHODS',\n",
       "  'text': 'pain was assessed using the visual analog pain scale ( @-@ mm ) .',\n",
       "  'line_number': 3,\n",
       "  'total_lines': 11},\n",
       " {'target': 'METHODS',\n",
       "  'text': 'secondary outcome measures included the western ontario and mcmaster universities osteoarthritis index scores , patient global assessment ( pga ) of the severity of knee oa , and @-min walk distance ( @mwd ) .',\n",
       "  'line_number': 4,\n",
       "  'total_lines': 11},\n",
       " {'target': 'METHODS',\n",
       "  'text': 'serum levels of interleukin @ ( il-@ ) , il-@ , tumor necrosis factor ( tnf ) - , and high-sensitivity c-reactive protein ( hscrp ) were measured .',\n",
       "  'line_number': 5,\n",
       "  'total_lines': 11},\n",
       " {'target': 'RESULTS',\n",
       "  'text': 'there was a clinically relevant reduction in the intervention group compared to the placebo group for knee pain , physical function , pga , and @mwd at @ weeks .',\n",
       "  'line_number': 6,\n",
       "  'total_lines': 11},\n",
       " {'target': 'RESULTS',\n",
       "  'text': 'the mean difference between treatment arms ( @ % ci ) was @ ( @-@ @ ) , p < @ ; @ ( @-@ @ ) , p < @ ; @ ( @-@ @ ) , p < @ ; and @ ( @-@ @ ) , p < @ , respectively .',\n",
       "  'line_number': 7,\n",
       "  'total_lines': 11},\n",
       " {'target': 'RESULTS',\n",
       "  'text': 'further , there was a clinically relevant reduction in the serum levels of il-@ , il-@ , tnf - , and hscrp at @ weeks in the intervention group when compared to the placebo group .',\n",
       "  'line_number': 8,\n",
       "  'total_lines': 11},\n",
       " {'target': 'RESULTS',\n",
       "  'text': 'these differences remained significant at @ weeks .',\n",
       "  'line_number': 9,\n",
       "  'total_lines': 11},\n",
       " {'target': 'RESULTS',\n",
       "  'text': 'the outcome measures in rheumatology clinical trials-osteoarthritis research society international responder rate was @ % in the intervention group and @ % in the placebo group ( p < @ ) .',\n",
       "  'line_number': 10,\n",
       "  'total_lines': 11},\n",
       " {'target': 'CONCLUSIONS',\n",
       "  'text': 'low-dose oral prednisolone had both a short-term and a longer sustained effect resulting in less knee pain , better physical function , and attenuation of systemic inflammation in older patients with knee oa ( clinicaltrials.gov identifier nct@ ) .',\n",
       "  'line_number': 11,\n",
       "  'total_lines': 11}]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the first abstract of our training data\n",
    "train_samples[:12]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79f48bcd",
   "metadata": {},
   "source": [
    "Let's create dataframes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2064195d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>text</th>\n",
       "      <th>line_number</th>\n",
       "      <th>total_lines</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>OBJECTIVE</td>\n",
       "      <td>to investigate the efficacy of @ weeks of dail...</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>METHODS</td>\n",
       "      <td>a total of @ patients with primary knee oa wer...</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>METHODS</td>\n",
       "      <td>outcome measures included pain reduction and i...</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>METHODS</td>\n",
       "      <td>pain was assessed using the visual analog pain...</td>\n",
       "      <td>3</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>METHODS</td>\n",
       "      <td>secondary outcome measures included the wester...</td>\n",
       "      <td>4</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      target                                               text  line_number  \\\n",
       "0  OBJECTIVE  to investigate the efficacy of @ weeks of dail...            0   \n",
       "1    METHODS  a total of @ patients with primary knee oa wer...            1   \n",
       "2    METHODS  outcome measures included pain reduction and i...            2   \n",
       "3    METHODS  pain was assessed using the visual analog pain...            3   \n",
       "4    METHODS  secondary outcome measures included the wester...            4   \n",
       "\n",
       "   total_lines  \n",
       "0           11  \n",
       "1           11  \n",
       "2           11  \n",
       "3           11  \n",
       "4           11  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = pd.DataFrame(train_samples)\n",
    "val_df = pd.DataFrame(val_samples)\n",
    "test_df = pd.DataFrame(test_samples)\n",
    "\n",
    "train_df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9855ab61",
   "metadata": {},
   "source": [
    "<a name=\"4.2\"></a>\n",
    "### <b> <font color='#1F618D'> 4.2. More visualization </font> </b>\n",
    "\n",
    "#### Number of classes and class balance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4953cc4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_classes = train_df['target'].nunique()\n",
    "num_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "42bac68f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "METHODS        0.329666\n",
       "RESULTS        0.321890\n",
       "CONCLUSIONS    0.150900\n",
       "BACKGROUND     0.120679\n",
       "OBJECTIVE      0.076866\n",
       "Name: target, dtype: float64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Distribution of labels in training data\n",
    "train_df.target.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a250b7c",
   "metadata": {},
   "source": [
    "#### Total lines distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "32bc84c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_hist(train_df['total_lines'], 'Distribution', 'Total lines', 'Frequency', 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e008a98b",
   "metadata": {},
   "source": [
    "#### Sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "538361e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(180040, 30212, 30135)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert abstract text lines into lists\n",
    "train_sentences = train_df[\"text\"].tolist()\n",
    "val_sentences = val_df[\"text\"].tolist()\n",
    "test_sentences = test_df[\"text\"].tolist()\n",
    "len(train_sentences), len(val_sentences), len(test_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7bd78189",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['to investigate the efficacy of @ weeks of daily low-dose oral prednisolone in improving pain , mobility , and systemic low-grade inflammation in the short term and whether the effect would be sustained at @ weeks in older adults with moderate to severe knee osteoarthritis ( oa ) .',\n",
       " 'a total of @ patients with primary knee oa were randomized @:@ ; @ received @ mg/day of prednisolone and @ received placebo for @ weeks .',\n",
       " 'outcome measures included pain reduction and improvement in function scores and systemic inflammation markers .',\n",
       " 'pain was assessed using the visual analog pain scale ( @-@ mm ) .',\n",
       " 'secondary outcome measures included the western ontario and mcmaster universities osteoarthritis index scores , patient global assessment ( pga ) of the severity of knee oa , and @-min walk distance ( @mwd ) .']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# View 5 lines of training sentences\n",
    "train_sentences[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "73b20a7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26.338269273494777"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# How long is each sentence on average?\n",
    "sent_lens = [len(sentence.split()) for sentence in train_sentences]\n",
    "avg_sent_len = np.mean(sent_lens)\n",
    "avg_sent_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e0256e8b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_hist(train_df['total_lines'], 'Distribution', 'Sentence length', 'Frequency', 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "38f90161",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "55"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# How long of a sentence lenght covers 95% of examples?\n",
    "output_seq_len = int(np.percentile(sent_lens, 95))\n",
    "output_seq_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d91a3ba4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "296"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Maximum sequence length in the training set\n",
    "max(sent_lens)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1fdc981",
   "metadata": {},
   "source": [
    "<a name=\"4.3\"></a>\n",
    "### <b> <font color='#1F618D'> 4.3. Categorical Data </font> </b>\n",
    "\n",
    "We will use one-hot encoding for our targets, since there are no ordinal relationship between them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a39e049",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "one_hot_encoder = OneHotEncoder(sparse=False, handle_unknown='ignore') # we want non-sparse matrix\n",
    "train_labels_one_hot = one_hot_encoder.fit_transform(train_df[\"target\"].to_numpy().reshape(-1, 1))\n",
    "\n",
    "# here there is no fit, we fit with the training data only\n",
    "val_labels_one_hot = one_hot_encoder.transform(val_df[\"target\"].to_numpy().reshape(-1, 1))\n",
    "test_labels_one_hot = one_hot_encoder.transform(test_df[\"target\"].to_numpy().reshape(-1, 1))\n",
    "\n",
    "# check what one hot encoded labels look like\n",
    "train_labels_one_hot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55811dde",
   "metadata": {},
   "source": [
    "<a name=\"4.4\"></a>\n",
    "### <b> <font color='#1F618D'> 4.4. Pre-processing for NLP </font> </b>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "845a3d1a",
   "metadata": {},
   "source": [
    "#### Create text vectorizer layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38aef1cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# How many words are in our vocab? (taken from table 2 in: https://arxiv.org/pdf/1710.06071.pdf)\n",
    "max_tokens = 68000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b01b7b94",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from tensorflow.keras.layers.experimental.preprocessing import TextVectorization\n",
    "from tensorflow.keras.layers import TextVectorization\n",
    "\n",
    "\n",
    "# Create text vectorizer\n",
    "text_vectorizer = TextVectorization(max_tokens=max_tokens, # number of words in vocabulary\n",
    "                                    output_sequence_length=output_seq_len) # desired output length of vectorized sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebae3f56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adapt text vectorizer to training sentences\n",
    "text_vectorizer.adapt(train_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4d54233",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_sentence = random.choice(train_sentences)\n",
    "print(f\"Text:\\n{target_sentence}\")\n",
    "print(f\"\\nLength of text: {len(target_sentence.split())}\")\n",
    "print(f\"\\nVectorized text: {text_vectorizer([target_sentence])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af05a8b4",
   "metadata": {},
   "source": [
    "Let's observe that it pads with zeros up to the specified output sequence length (output_seq_length, which is 55 in this case)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a67ea86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# How many words in our training vocabulary\n",
    "rct_20k_text_vocab = text_vectorizer.get_vocabulary()\n",
    "print(f\"Number of words in vocab: {len(rct_20k_text_vocab)}\")\n",
    "print(f\"Most common words in the vocab: {rct_20k_text_vocab[:5]}\")\n",
    "print(f\"Least common words in the vocab: {rct_20k_text_vocab[-5:]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a281a0d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the config of our text vectorizer\n",
    "text_vectorizer.get_config()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cfc65f7",
   "metadata": {},
   "source": [
    "<b> \n",
    "We will apply it later as the first layer of the model after obtaining the input. </b>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7ce2aee",
   "metadata": {},
   "source": [
    "<a name=\"4.5\"></a>\n",
    "### <b> <font color='#1F618D'> 4.5. Creating tensorflow datasets </font> </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87b190fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Turn our data into TensorFlow Datasets\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((train_sentences, train_labels_one_hot))\n",
    "valid_dataset = tf.data.Dataset.from_tensor_slices((val_sentences, val_labels_one_hot))\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices((test_sentences, test_labels_one_hot))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b73558ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "for x, y in train_dataset.take(1):\n",
    "    print(f\"Text: {x}\\n\")\n",
    "    print(f\"Label: {y}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0c509c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take the TensorSliceDataset's and turn them into prefected datasets\n",
    "train_dataset = train_dataset.batch(32).prefetch(tf.data.AUTOTUNE)\n",
    "valid_dataset = valid_dataset.batch(32).prefetch(tf.data.AUTOTUNE)\n",
    "test_dataset = test_dataset.batch(32).prefetch(tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01b0a4c5",
   "metadata": {},
   "source": [
    "<a name=\"5\"></a>\n",
    "## <b> <font color='blue'> 5. Models </font> </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "036246e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import store_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b793bae2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to save results and compare\n",
    "results = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31edf409",
   "metadata": {},
   "outputs": [],
   "source": [
    "# constants\n",
    "INPUT_SHAPE=(1,)\n",
    "BATCH_SIZE = 32\n",
    "NUM_CLASSES=num_classes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18da8219",
   "metadata": {},
   "source": [
    "<a name=\"5.1\"></a>\n",
    "### <b> <font color='#1F618D'> 5.1. Embedding layer </font> </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d051b4dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create token embedding layer\n",
    "token_embed = layers.Embedding(input_dim=len(rct_20k_text_vocab), # length of vocabulary\n",
    "                               output_dim=128, # Note: different embedding sizes result in drastically differnt \n",
    "                                               #numbers of parameters to train\n",
    "                               mask_zero=True, # use masking to handle variable sequence lengths (save space),\n",
    "                               name=\"token_embedding\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6d7f0c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show example embedding\n",
    "print(f\"Sentence before vectorization:\\n {target_sentence}\\n\")\n",
    "vectorized_sentence = text_vectorizer([target_sentence])\n",
    "print(f\"Sentence after vectorization (before embedding):\\n {vectorized_sentence}\\n\")\n",
    "embedded_sentence = token_embed(vectorized_sentence)\n",
    "print(f\"Sentence after embedding:\\n {embedded_sentence}\\n\")\n",
    "print(f\"Embedded sentence shape: {embedded_sentence.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f492e0b",
   "metadata": {},
   "source": [
    "<a name=\"5.2\"></a>\n",
    "### <b> <font color='#1F618D'> 5.2. Trying different models </font> </b>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14b8b571",
   "metadata": {},
   "source": [
    "<a name=\"5.2.1\"></a>\n",
    "### <b> <font color='#5499C7'> 5.2.1. Model 1: Conv1D </font> </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a882d51",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model_1(name, input_shape = INPUT_SHAPE, num_classes = NUM_CLASSES):\n",
    "    inputs = layers.Input(shape=input_shape,dtype=tf.string)\n",
    "    x = text_vectorizer(inputs)\n",
    "    x = token_embed(x)\n",
    "    x = layers.Conv1D(64, kernel_size=5, padding=\"same\", activation=\"relu\")(x)\n",
    "    x = tf.keras.layers.GlobalAveragePooling1D()(x)\n",
    "    outputs = tf.keras.layers.Dense(num_classes, activation='softmax')(x)\n",
    "    model = tf.keras.Model(inputs,outputs,name=name)\n",
    "    return model\n",
    "\n",
    "\n",
    "model_1 = build_model_1('model_1')\n",
    "\n",
    "model_1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac3cf48f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_1.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(),\n",
    "    loss=tf.keras.losses.CategoricalCrossentropy(), # one-hot encoded labels\n",
    "    metrics=['accuracy', 'Precision', 'Recall']\n",
    ")\n",
    "\n",
    "\n",
    "history_model_1 = model_1.fit(\n",
    "    train_dataset,\n",
    "    steps_per_epoch=int(0.1*len(train_dataset)),\n",
    "    epochs=3,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    validation_data=valid_dataset,\n",
    "    validation_steps=int(0.1 * len(valid_dataset))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0101e4da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save model\n",
    "model_1.save('models/Model_1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11da5f4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_model_1 = tf.keras.models.load_model('models/Model_1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e0a176f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate\n",
    "score1 = loaded_model_1.evaluate(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f80c3858",
   "metadata": {},
   "outputs": [],
   "source": [
    "store_results(results, 'Model 1', score1);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5627f036",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions (our model predicts prediction probabilities for each class)\n",
    "model_1_pred_probs = loaded_model_1.predict(valid_dataset)\n",
    "model_1_pred_probs, model_1_pred_probs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4530eba7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert pred probs to classes\n",
    "model_1_preds = tf.argmax(model_1_pred_probs, axis=1)\n",
    "model_1_preds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdcafd19",
   "metadata": {},
   "source": [
    "<a name=\"5.2.2\"></a>\n",
    "### <b> <font color='#5499C7'> 5.2.2. Model 2: Feature extraction with pre-trained token embeddings </font> </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48577412",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_hub as hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc098929",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_hub_embedding_layer = hub.KerasLayer(\"https://tfhub.dev/google/universal-sentence-encoder/4\",\n",
    "                                        trainable=False,\n",
    "                                        name=\"universal_sentence_encoder\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e45e966",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test out the pretrained embedding on a random sentence \n",
    "random_train_sentence = random.choice(train_sentences)\n",
    "print(f\"Random sentence:\\n {random_train_sentence}\")\n",
    "use_embedded_sentence = tf_hub_embedding_layer([random_train_sentence])\n",
    "print(f\"Setence after embedding:\\n{use_embedded_sentence[0][:30]}\\n\")\n",
    "print(f\"Length of sentence embedding: {len(use_embedded_sentence[0])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b49c8dc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model_2(name, input_shape=INPUT_SHAPE, num_classes=NUM_CLASSES):\n",
    "    inputs = layers.Input(shape=input_shape, dtype=tf.string)\n",
    "    x = tf_hub_embedding_layer()(inputs)\n",
    "    x = tf.keras.layers.Dense(128,activation='relu')(x)\n",
    "    outputs = tf.keras.layers.Dense(num_classes,activation='softmax')(x)\n",
    "    model = tf.keras.Model(inputs,outputs,name=name)\n",
    "    return model\n",
    "\n",
    "\n",
    "model_2 = build_model_1('model_2_USE_feature_extractor')\n",
    "    \n",
    "model_2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5454d5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_2.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(),\n",
    "    loss=tf.keras.losses.CategoricalCrossentropy(), # one-hot encoded labels\n",
    "    metrics=['accuracy', 'Precision', 'Recall']\n",
    ")\n",
    "\n",
    "\n",
    "history_model_2 = model_2.fit(\n",
    "    train_dataset,\n",
    "    steps_per_epoch=int(0.1*len(train_dataset)),\n",
    "    epochs=3,\n",
    "    validation_data=valid_dataset,\n",
    "    validation_steps=int(0.1 * len(valid_dataset))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d545dc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_2.save('models/Model2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3ed9189",
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_model_2 = tf.keras.models.load_model('models/Model2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8bf214c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate\n",
    "score2 = loaded_model_2.evaluate(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "883d6448",
   "metadata": {},
   "outputs": [],
   "source": [
    "store_results(results, 'Model 2', score2);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d921ed5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions with feature extraction model\n",
    "model_2_pred_probs = loaded_model_2.predict(valid_dataset)\n",
    "model_2_pred_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b28738f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the prediction probabilities found with feature extraction model to labels\n",
    "model_2_preds = tf.argmax(model_2_pred_probs, axis=1)\n",
    "model_2_preds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d11cf55e",
   "metadata": {},
   "source": [
    "<a name=\"5.2.3\"></a>\n",
    "### <b> <font color='#5499C7'> 5.2.3. Model 3: Conv1D with character embeddings </font> </b>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "871f2855",
   "metadata": {},
   "source": [
    "#### Creating a character-level tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c0e7263",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sentences[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ed0e91f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make function to split sentences into characters\n",
    "def split_chars(text):\n",
    "  return \" \".join(list(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a048873b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split sequence-level data splits into character-level data splits\n",
    "train_chars = [split_chars(sentence) for sentence in train_sentences]\n",
    "val_chars = [split_chars(sentence) for sentence in val_sentences]\n",
    "test_chars = [split_chars(sentence) for sentence in test_sentences]\n",
    "train_chars[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e7152ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# What's the average character length?\n",
    "char_lens = [len(sentence) for sentence in train_sentences]\n",
    "mean_char_len = np.mean(char_lens)\n",
    "mean_char_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc861543",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear el histograma\n",
    "n, bins, patches = plt.hist(char_lens, bins=5, edgecolor='black')\n",
    "\n",
    "# Colores para cada barra\n",
    "colors = ['blue', 'cyan', 'green', 'purple', 'orange']\n",
    "\n",
    "# Asignar un color a cada barra\n",
    "for patch, color in zip(patches, colors):\n",
    "    patch.set_facecolor(color)\n",
    "\n",
    "# Mostrar el gr√°fico\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab5dfbec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find what character length covers 95% of sequences\n",
    "output_seq_char_len = int(np.percentile(char_lens, 95))\n",
    "output_seq_char_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8cfe955",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all keyboard characters\n",
    "alphabet = string.ascii_lowercase + string.digits + string.punctuation\n",
    "alphabet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7895f328",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create char-level token vectorizer instance\n",
    "NUM_CHAR_TOKENS = len(alphabet) + 2 # add 2 for space and OOV token (OOV = out of vocab, '[UNK]')\n",
    "\n",
    "char_vectorizer = TextVectorization(max_tokens=NUM_CHAR_TOKENS,\n",
    "                                    output_sequence_length=output_seq_char_len,\n",
    "                                    # standardize=None, # set standardization to \"None\" if you want to leave punctuation in\n",
    "                                    name=\"char_vectorizer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8de79ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adapt character vectorizer to training character\n",
    "char_vectorizer.adapt(train_chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4107f430",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check character vocab stats\n",
    "char_vocab = char_vectorizer.get_vocabulary()\n",
    "print(f\"Number of different characters in character vocab: {len(char_vocab)}\")\n",
    "print(f\"5 most common characters: {char_vocab[:5]}\")\n",
    "print(f\"5 least common characters: {char_vocab[-5:]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f92a1d15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test out character vectorizer\n",
    "random_train_chars = random.choice(train_chars)\n",
    "print(f\"Charified text:\\n {random_train_chars}\")\n",
    "print(f\"\\nLength of random_train_chars: {len(random_train_chars.split())}\")\n",
    "vectorized_chars = char_vectorizer([random_train_chars])\n",
    "print(f\"\\nVectorized chars:\\n {vectorized_chars}\")\n",
    "print(f\"\\nLength of vectorized chars: {len(vectorized_chars[0])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16b29167",
   "metadata": {},
   "source": [
    "#### Creating a character-level embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c2eeb9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create char embedding layer\n",
    "char_embed = layers.Embedding(input_dim=len(char_vocab), # number of different characters\n",
    "                              output_dim=25, # this is the size of the char embedding in the paper: https://arxiv.org/pdf/1612.05251.pdf (Figure 1)\n",
    "                              mask_zero=True,\n",
    "                              name=\"char_embed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eb6a3d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test our character embedding layer\n",
    "print(f\"Charified text:\\n {random_train_chars}\\n\")\n",
    "char_embed_example = char_embed(char_vectorizer([random_train_chars]))\n",
    "print(f\"Embedded chars (after vectorization and embedding):\\n {char_embed_example}\\n\")\n",
    "print(f\"Character embedding shape: {char_embed_example.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b7b0288",
   "metadata": {},
   "source": [
    "Each sentence has length 290 and the size of the embedding is 25."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5549bff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create char level datasets\n",
    "train_char_dataset = tf.data.Dataset.from_tensor_slices((train_chars, train_labels_one_hot)).batch(32).prefetch(tf.data.AUTOTUNE)\n",
    "val_char_dataset = tf.data.Dataset.from_tensor_slices((val_chars, val_labels_one_hot)).batch(32).prefetch(tf.data.AUTOTUNE)\n",
    "test_char_dataset = tf.data.Dataset.from_tensor_slices((test_chars, test_labels_one_hot)).batch(32).prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "train_char_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3385f724",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model_3(name, input_shape=INPUT_SHAPE, num_classes=NUM_CLASSES):\n",
    "    inputs = layers.Input(shape=input_shape,dtype=tf.string)\n",
    "    x = char_vectorizer(inputs)\n",
    "    x = char_embed(x)\n",
    "    x = layers.Conv1D(64, kernel_size=5, padding=\"same\", activation=\"relu\")(x)\n",
    "    x = tf.keras.layers.GlobalAveragePooling1D()(x) # try MaxPooling!!\n",
    "    outputs = tf.keras.layers.Dense(num_classes, activation='softmax')(x)\n",
    "    model = tf.keras.Model(inputs,outputs,name=name)\n",
    "    return model\n",
    "\n",
    "    \n",
    "model_3 = build_model_3('model_3')\n",
    "\n",
    "model_3.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "754f170c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile\n",
    "model_3.compile(loss=\"categorical_crossentropy\",\n",
    "                optimizer=tf.keras.optimizers.Adam(),\n",
    "                metrics=[\"accuracy\", 'Precision', 'Recall'])\n",
    "\n",
    "# Fit the model on chars only\n",
    "model_3_history = model_3.fit(train_char_dataset,\n",
    "                              steps_per_epoch=int(0.1*len(train_char_dataset)),\n",
    "                              epochs=3,\n",
    "                              validation_data=val_char_dataset,\n",
    "                              validation_steps=int(0.1*len(val_char_dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc59ee13",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_3.save('models/Model_3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47175d26",
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_model_3 = tf.keras.models.load_model('models/Model_3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a05a260e",
   "metadata": {},
   "outputs": [],
   "source": [
    "score3 = loaded_model_3.evaluate(test_char_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fb158b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "store_results(results, 'Model 3', score3);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6da18a08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions with character model only\n",
    "model_3_pred_probs = loaded_model_3.predict(val_char_dataset)\n",
    "model_3_pred_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f012b7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert prediction probabilities to class labels\n",
    "model_3_preds = tf.argmax(model_3_pred_probs, axis=1)\n",
    "model_3_preds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "327ce24c",
   "metadata": {},
   "source": [
    "<a name=\"5.2.4\"></a>\n",
    "### <b> <font color='#5499C7'> 5.2.4. Model 4: Combining pretrained token embeddings + characters embeddings (hybrid embedding layer) </font> </b>\n",
    "\n",
    "1. Create a token-level embedding model (similar `model_1`)\n",
    "2. Create a character-level model (similar to `model_3` with a slight modification)\n",
    "3. Combine 1 & 2 with a concatenate (`layers.Concatenate`) \n",
    "4. Build a series of output layers on top of 3 similar to Figure 1 and section 4.2 of https://arxiv.org/pdf/1612.05251.pdf\n",
    "5. Construct a model which takes token and character-level sequences as input and produces sequence label probabilities as output.\n",
    "\n",
    "<img src=\"images/model_4.png\">\n",
    "\n",
    "\n",
    "<br>\n",
    "<center> <b>Figure</b> Model.</center>\n",
    "\n",
    "cr√©dtiso a la imagen!!!\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "488bfbea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine chars and tokens into a dataset\n",
    "train_char_token_data = tf.data.Dataset.from_tensor_slices((train_sentences, train_chars)) # make data\n",
    "train_char_token_labels = tf.data.Dataset.from_tensor_slices(train_labels_one_hot) # make labels\n",
    "train_char_token_dataset = tf.data.Dataset.zip((train_char_token_data, train_char_token_labels)) \n",
    "        # combine data and labels\n",
    "\n",
    "# Prefetch and batch train data\n",
    "train_char_token_dataset = train_char_token_dataset.batch(32).prefetch(tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8672010c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Repeat the above steps for our validation data\n",
    "val_char_token_data = tf.data.Dataset.from_tensor_slices((val_sentences, val_chars)) # make data\n",
    "val_char_token_labels = tf.data.Dataset.from_tensor_slices(val_labels_one_hot) # make labels\n",
    "val_char_token_dataset = tf.data.Dataset.zip((val_char_token_data, val_char_token_labels)) # combine data and labels\n",
    "val_char_token_dataset = val_char_token_dataset.batch(32).prefetch(tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92342c88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Repeat the above steps for our test data\n",
    "test_char_token_data = tf.data.Dataset.from_tensor_slices((test_sentences, test_chars)) # make data\n",
    "test_char_token_labels = tf.data.Dataset.from_tensor_slices(test_labels_one_hot) # make labels\n",
    "test_char_token_dataset = tf.data.Dataset.zip((test_char_token_data, test_char_token_labels)) # combine data and labels\n",
    "test_char_token_dataset = test_char_token_dataset.batch(32).prefetch(tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70733cd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check out our training char and token embedding dataset\n",
    "train_char_token_dataset, val_char_token_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afbeb09c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model_4(name):\n",
    "    # 1. Setup token inputs/model\n",
    "    token_inputs = layers.Input(shape=[], dtype=tf.string, name=\"token_input\")\n",
    "    token_embeddings = tf_hub_embedding_layer(token_inputs)\n",
    "    token_outputs = layers.Dense(128, activation=\"relu\")(token_embeddings)\n",
    "    token_model = tf.keras.Model(inputs=token_inputs,\n",
    "                                 outputs=token_outputs)\n",
    "\n",
    "    # 2. Setup char inputs/model\n",
    "    char_inputs = layers.Input(shape=(1,), dtype=tf.string, name=\"char_input\")\n",
    "    char_vectors = char_vectorizer(char_inputs)\n",
    "    char_embeddings = char_embed(char_vectors)\n",
    "    char_bi_lstm = layers.Bidirectional(layers.LSTM(24))(char_embeddings)\n",
    "    char_model = tf.keras.Model(inputs=char_inputs,\n",
    "                                outputs=char_bi_lstm)\n",
    "\n",
    "    # 3. Concatenate token and char inputs (create hybrid token embedding)\n",
    "    token_char_concat = layers.Concatenate(name=\"token_char_hybrid\")([token_model.output,\n",
    "                                                                      char_model.output])\n",
    "\n",
    "    # 4. Create output layers\n",
    "    combined_dropout = layers.Dropout(0.5)(token_char_concat)\n",
    "    combined_dense = layers.Dense(128, activation=\"relu\")(combined_dropout)\n",
    "    final_dropout = layers.Dropout(0.5)(combined_dense)\n",
    "    output_layer = layers.Dense(num_classes, activation=\"softmax\")(final_dropout)\n",
    "\n",
    "    # 5. Construct model with char and token inputs\n",
    "    model = tf.keras.Model(inputs=[token_model.input, char_model.input],\n",
    "                             outputs=output_layer,\n",
    "                             name=\"model_4_token_and_char_embeddings\")\n",
    "    #\n",
    "    return model\n",
    "\n",
    "\n",
    "model_4 = build_model_4('Model 4')\n",
    "\n",
    "model_4.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a48dc1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to plot the model\n",
    "from keras.utils import plot_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9da0ca82",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_model(model_4, show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aec3e7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile token char model\n",
    "model_4.compile(loss=\"categorical_crossentropy\",\n",
    "                optimizer=tf.keras.optimizers.Adam(), # section 4.2 of the paper says they use SGD, you might want to try this\n",
    "                metrics=[\"accuracy\", 'Precision', 'Recall'])\n",
    "\n",
    "# Fit the model on tokens and chars\n",
    "history_model_4 = model_4.fit(train_char_token_dataset,\n",
    "                              steps_per_epoch=int(0.1 * len(train_char_token_dataset)),\n",
    "                              epochs=3,\n",
    "                              validation_data=val_char_token_dataset,\n",
    "                              validation_steps=int(0.1 * len(val_char_token_dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3840585",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_4.save('models/Model_4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34091a0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "score4 = model_4.evaluate(test_char_token_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1daf8685",
   "metadata": {},
   "outputs": [],
   "source": [
    "store_results(results, 'Model 4', score4);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6686031",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions using the token-character model hybrid\n",
    "model_4_pred_probs = model_4.predict(test_char_token_dataset)\n",
    "model_4_pred_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40a6b1a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Format pred probs into pred labels\n",
    "model_4_preds = tf.argmax(model_4_pred_probs, axis=1)\n",
    "model_4_preds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a5c84a1",
   "metadata": {},
   "source": [
    "<a name=\"5.2.5\"></a>\n",
    "### <b> <font color='#5499C7'> 5.2.5. Model 5: Transfer learning with pretrained token embeddings + character embeddings + positional embeddings</font> </b>\n",
    "\n",
    "We are going to include positional embeddings because order is important; if a sentence is the first in an abstract, it is more likely to be the objective or the background, if it is the last one, it is more likely to be the conclusion..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50d3c9d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abb3fd41",
   "metadata": {},
   "source": [
    "> üîë **Note:** Any engineered features used to train a model need to be available at test time. In our case, line numbers and total lines are available."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2fba238",
   "metadata": {},
   "source": [
    "#### Create positional embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f662fe62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# How many different line numbers are there?\n",
    "train_df[\"line_number\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f18ad4ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the distribution of \"line_number\" column\n",
    "plot_hist(train_df['line_number'], 'Distribution of line number', 'Line number', 'Frequency', bins_number = 10)    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6048c6e1",
   "metadata": {},
   "source": [
    "We cut it into 15 so that the vector is not too long, and as seen in the previous histogram,\n",
    "the majority of our data falls in there."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "901cf01e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use TensorFlow to create one-hot-encoded tensors of our \"line_number\" column\n",
    "train_line_numbers_one_hot = tf.one_hot(train_df[\"line_number\"].to_numpy(), depth=15)\n",
    "val_line_numbers_one_hot = tf.one_hot(val_df[\"line_number\"].to_numpy(), depth=15)\n",
    "test_line_numbers_one_hot = tf.one_hot(test_df[\"line_number\"].to_numpy(), depth=15)\n",
    "\n",
    "train_line_numbers_one_hot[:14], train_line_numbers_one_hot.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7c2e6a2",
   "metadata": {},
   "source": [
    "Now we've encoded our line numbers feature, let's do the same for our total lines feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "accb742f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# How many different numbers of lines are there?\n",
    "train_df[\"total_lines\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0ee3539",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the distribution of \"line_number\" column\n",
    "plot_hist(train_df['total_lines'], title='Distribution', 'Total lines', 'Frequency', bins_number = 10) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53a00ee7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the coverage of a \"total_lines\" value of 20\n",
    "np.percentile(train_df.total_lines, 98)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48b8a0b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use TensorFlow to create one-hot-encoded tensors of our \"total_lines\" feature\n",
    "train_total_lines_one_hot = tf.one_hot(train_df[\"total_lines\"].to_numpy(), depth=20)\n",
    "val_total_lines_one_hot = tf.one_hot(val_df[\"total_lines\"].to_numpy(), depth=20)\n",
    "test_total_lines_one_hot = tf.one_hot(test_df[\"total_lines\"].to_numpy(), depth=20)\n",
    "train_total_lines_one_hot.shape, train_total_lines_one_hot[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9f97c20",
   "metadata": {},
   "source": [
    "#### Building a tribrid embedding model\n",
    "\n",
    "1. Create a token-level model\n",
    "2. Create a character-level model\n",
    "3. Create a model for the \"line_number\" feature\n",
    "4. Create a model for the \"total_lines\" feature\n",
    "5. Combine the outputs of 1 & 2 using tf.keras.layers.Concatenate\n",
    "6. Combine the outputs of 3, 4, 5 using tf.keras.layers.Concatenate\n",
    "7. Create an output layer to accept the tribrid embedding and output label probabilities \n",
    "8. Combine the inputs of 1, 2, 3, 4 and outputs of into a tf.keras.Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68da38e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create training and valiadation datasets (with all four kinds of input data)\n",
    "train_char_token_pos_data = tf.data.Dataset.from_tensor_slices((train_line_numbers_one_hot,\n",
    "                                                                train_total_lines_one_hot,\n",
    "                                                                train_sentences,\n",
    "                                                                train_chars))\n",
    "train_char_token_pos_labels = tf.data.Dataset.from_tensor_slices(train_labels_one_hot)\n",
    "train_char_token_pos_dataset = tf.data.Dataset.zip((train_char_token_pos_data, train_char_token_pos_labels))\n",
    "train_char_token_pos_dataset = train_char_token_pos_dataset.batch(32).prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "# Do the same as above but for the validation dataset\n",
    "val_char_token_pos_data = tf.data.Dataset.from_tensor_slices((val_line_numbers_one_hot,\n",
    "                                                              val_total_lines_one_hot,\n",
    "                                                              val_sentences,\n",
    "                                                              val_chars))\n",
    "val_char_token_pos_labels = tf.data.Dataset.from_tensor_slices(val_labels_one_hot)\n",
    "val_char_token_pos_dataset = tf.data.Dataset.zip((val_char_token_pos_data, val_char_token_pos_labels))\n",
    "val_char_token_pos_dataset = val_char_token_pos_dataset.batch(32).prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "# Do the same for test\n",
    "test_char_token_pos_data = tf.data.Dataset.from_tensor_slices((test_line_numbers_one_hot,\n",
    "                                                              test_total_lines_one_hot,\n",
    "                                                              test_sentences,\n",
    "                                                              test_chars))\n",
    "test_char_token_pos_labels = tf.data.Dataset.from_tensor_slices(test_labels_one_hot)\n",
    "test_char_token_pos_dataset = tf.data.Dataset.zip((test_char_token_pos_data, test_char_token_pos_labels))\n",
    "test_char_token_pos_dataset = test_char_token_pos_dataset.batch(32).prefetch(tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4acbe62e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check input shapes\n",
    "train_char_token_pos_dataset, val_char_token_pos_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26aa5751",
   "metadata": {},
   "outputs": [],
   "source": [
    "# take the first element\n",
    "first_element_dataset = train_char_token_pos_dataset.take(1)\n",
    "\n",
    "# convert the dataset to a list and get the first element\n",
    "first_element = list(first_element_dataset.as_numpy_iterator())[0]\n",
    "\n",
    "first_element"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a450059a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model_5(name):\n",
    "    # 1. Token inputs\n",
    "    token_inputs = layers.Input(shape=[], dtype=\"string\", name=\"token_inputs\")\n",
    "    token_embeddings = tf_hub_embedding_layer(token_inputs)\n",
    "    token_outputs = layers.Dense(128, activation=\"relu\")(token_embeddings)\n",
    "    token_model = tf.keras.Model(inputs=token_inputs,\n",
    "                                 outputs=token_outputs)\n",
    "\n",
    "    # 2. Char inputs\n",
    "    char_inputs = layers.Input(shape=(1, ), dtype=\"string\", name=\"char_inputs\")\n",
    "    char_vectors = char_vectorizer(char_inputs)\n",
    "    char_embeddings = char_embed(char_vectors)\n",
    "    char_bi_lstm = layers.Bidirectional(layers.LSTM(24))(char_embeddings)\n",
    "    char_model = tf.keras.Model(inputs=char_inputs,\n",
    "                                outputs=char_bi_lstm)\n",
    "\n",
    "    # 3. Line numbers model\n",
    "    line_number_inputs = layers.Input(shape=(15,), dtype=tf.float32, name=\"line_number_input\")\n",
    "    x = layers.Dense(32, activation=\"relu\")(line_number_inputs)\n",
    "    # combine inputs & dense layer into model\n",
    "    line_number_model = tf.keras.Model(inputs=line_number_inputs,\n",
    "                                       outputs=x)\n",
    "\n",
    "    # 4. Total lines model\n",
    "    total_lines_inputs = layers.Input(shape=(20,), dtype=tf.float32, name=\"total_lines_input\")\n",
    "    y = layers.Dense(32, activation=\"relu\")(total_lines_inputs)\n",
    "    total_lines_model = tf.keras.Model(inputs=total_lines_inputs,\n",
    "                                       outputs=y)\n",
    "\n",
    "    # 5. Combine token and char embeddings into a hybrid embedding\n",
    "    combined_embeddings = layers.Concatenate(name=\"char_token_hybrid_embedding\")([token_model.output,\n",
    "                                                                                  char_model.output])\n",
    "\n",
    "    z = layers.Dense(256, activation=\"relu\")(combined_embeddings)\n",
    "    z = layers.Dropout(0.5)(z)\n",
    "\n",
    "    # 6. Combine positional embedding with combined token and char embeddings\n",
    "    tribrid_embeddings = layers.Concatenate(name=\"char_token_positional_embedding\")([line_number_model.output,\n",
    "                                                                                     total_lines_model.output,\n",
    "                                                                                     z])\n",
    "\n",
    "    # 7. Create output layer\n",
    "    output_layer = layers.Dense(num_classes, activation=\"softmax\", name=\"output_layer\")(tribrid_embeddings)\n",
    "\n",
    "    # 8. Put together model with all kinds of inputs\n",
    "    model = tf.keras.Model(inputs=[line_number_model.input,\n",
    "                                     total_lines_model.input,\n",
    "                                     token_model.input,\n",
    "                                     char_model.input],\n",
    "                             outputs=output_layer,\n",
    "                             name=name)\n",
    "    \n",
    "    # return\n",
    "    return model\n",
    "\n",
    "\n",
    "model_5 = build_model_5('Model_5')\n",
    "\n",
    "model_5.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "546e30cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_model(model_5, show_shapes=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0934513",
   "metadata": {},
   "source": [
    "What is label smoothing?\n",
    "\n",
    "For example, if our model gets too confident on a single class (e.g. its prediction probability is really high), it may get stuck on that class and not consider other classes...\n",
    "\n",
    "Really confident: `[0.0, 0.0, 1.0, 0.0, 0.0]` \n",
    "\n",
    "What label smoothing does is it assigns some of the value from the highest pred prob to other classes, in turn, hopefully improving generalization: `[0.01, 0.01, 0.96, 0.01, 0.01]` \n",
    "\n",
    "> üìñ **Resource:** For more on label smoothing, see this blog post from PyImageSearch: https://www.pyimagesearch.com/2019/12/30/label-smoothing-with-keras-tensorflow-and-deep-learning/ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6051ccfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile token, char, and positional embedding model\n",
    "model_5.compile(loss=tf.keras.losses.CategoricalCrossentropy(label_smoothing=0.2), # helps to prevent overfitting\n",
    "                optimizer=tf.keras.optimizers.Adam(),\n",
    "                metrics=['accuracy', 'Precision', 'Recall'])\n",
    "\n",
    "# Fit our tribrid embedding model\n",
    "history_model_5 = model_5.fit(train_char_token_pos_dataset,\n",
    "                              steps_per_epoch=int(0.1 * len(train_char_token_pos_dataset)),\n",
    "                              epochs=3,\n",
    "                              validation_data=val_char_token_pos_dataset,\n",
    "                              validation_steps=int(0.1 * len(val_char_token_pos_dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb575411",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_5.save('Model_5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaee358d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the model from SavedModel format\n",
    "loaded_model_5 = tf.keras.models.load_model('Model_5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e6cb896",
   "metadata": {},
   "outputs": [],
   "source": [
    "score5 = loaded_model_5.evaluate(test_char_token_pos_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "696aaf16",
   "metadata": {},
   "outputs": [],
   "source": [
    "store_results(results, 'Model 5', score5);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c49d1dd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions \n",
    "model_5_pred_probs = loaded_model_5.predict(test_char_token_pos_dataset)\n",
    "model_5_pred_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfc7c077",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Format pred probs into pred labels\n",
    "model_5_preds = tf.argmax(model_5_pred_probs, axis=1)\n",
    "model_5_preds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "930de694",
   "metadata": {},
   "source": [
    "<a name=\"6\"></a>\n",
    "## <b> <font color='blue'> 6. Compare results </font> </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ed7c9055",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'results' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [27], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Convert dictionary to DataFrame\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m df_metrics \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(\u001b[43mresults\u001b[49m)\u001b[38;5;241m.\u001b[39mT  \u001b[38;5;66;03m# .T transposes the DataFrame for easier viewing\u001b[39;00m\n\u001b[1;32m      3\u001b[0m df_metrics\u001b[38;5;241m.\u001b[39mreset_index(inplace\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m      4\u001b[0m df_metrics\u001b[38;5;241m.\u001b[39mrename(columns\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mindex\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mModel\u001b[39m\u001b[38;5;124m'\u001b[39m}, inplace\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'results' is not defined"
     ]
    }
   ],
   "source": [
    "# Convert dictionary to DataFrame\n",
    "df_metrics = pd.DataFrame(results).T  # .T transposes the DataFrame for easier viewing\n",
    "df_metrics.reset_index(inplace=True)\n",
    "df_metrics.rename(columns={'index': 'Model'}, inplace=True)\n",
    "\n",
    "# Display the DataFrame\n",
    "df_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "cda3da43",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'results' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [28], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Extract data\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m models \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[43mresults\u001b[49m\u001b[38;5;241m.\u001b[39mkeys())\n\u001b[1;32m      3\u001b[0m metrics \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(results[models[\u001b[38;5;241m0\u001b[39m]]\u001b[38;5;241m.\u001b[39mkeys())\n\u001b[1;32m      4\u001b[0m values \u001b[38;5;241m=\u001b[39m {metric: [] \u001b[38;5;28;01mfor\u001b[39;00m metric \u001b[38;5;129;01min\u001b[39;00m metrics}\n",
      "\u001b[0;31mNameError\u001b[0m: name 'results' is not defined"
     ]
    }
   ],
   "source": [
    "# Extract data\n",
    "models = list(results.keys())\n",
    "metrics = list(results[models[0]].keys())\n",
    "values = {metric: [] for metric in metrics}\n",
    "\n",
    "for model in models:\n",
    "    for metric in metrics:\n",
    "        values[metric].append(results[model][metric])\n",
    "\n",
    "x = np.arange(len(models))  # the label locations\n",
    "width = 0.2  # the width of the bars\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "\n",
    "# Plot each metric\n",
    "for i, metric in enumerate(metrics):\n",
    "    ax.bar(x + i * width, values[metric], width, label=metric)\n",
    "\n",
    "# Add some text for labels, title and custom x-axis tick labels, etc.\n",
    "ax.set_xlabel('Models', fontweight='bold')\n",
    "ax.set_ylabel('Value', fontweight='bold')\n",
    "ax.set_title('Comparison of Models by Metrics', fontweight='bold', color='#12222C')\n",
    "ax.set_xticks(x + width * (len(metrics) / 2 - 0.5))\n",
    "ax.set_xticklabels(models)\n",
    "ax.legend()\n",
    "\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "106a6b27",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'metrics' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [29], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m fig, axs \u001b[38;5;241m=\u001b[39m plt\u001b[38;5;241m.\u001b[39msubplots(\u001b[38;5;28mlen\u001b[39m(\u001b[43mmetrics\u001b[49m), \u001b[38;5;241m1\u001b[39m, figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m8\u001b[39m, \u001b[38;5;241m6\u001b[39m), sharex\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, metric \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(metrics):\n\u001b[1;32m      4\u001b[0m     values \u001b[38;5;241m=\u001b[39m [results[model][metric] \u001b[38;5;28;01mfor\u001b[39;00m model \u001b[38;5;129;01min\u001b[39;00m models]\n",
      "\u001b[0;31mNameError\u001b[0m: name 'metrics' is not defined"
     ]
    }
   ],
   "source": [
    "fig, axs = plt.subplots(len(metrics), 1, figsize=(8, 6), sharex=True)\n",
    "\n",
    "for i, metric in enumerate(metrics):\n",
    "    values = [results[model][metric] for model in models]\n",
    "    axs[i].bar(models, values, color=['b', 'c', 'r', 'g', 'k', 'y', 'm'])\n",
    "    axs[i].set_title(f'{metric.capitalize()} Comparison', fontweight='bold', color='#1B4F72')\n",
    "    axs[i].set_ylabel('Value', fontweight='bold')\n",
    "\n",
    "axs[-1].set_xlabel('Models', fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1d5c7a85",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_metrics' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [30], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Find the index of the row with the highest F1 score\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m highest_f1_index \u001b[38;5;241m=\u001b[39m \u001b[43mdf_metrics\u001b[49m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mf1_score\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39midxmax()\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# Get the model with the highest F1 score\u001b[39;00m\n\u001b[1;32m      5\u001b[0m best_model \u001b[38;5;241m=\u001b[39m df_metrics\u001b[38;5;241m.\u001b[39mloc[highest_f1_index]\n",
      "\u001b[0;31mNameError\u001b[0m: name 'df_metrics' is not defined"
     ]
    }
   ],
   "source": [
    "# Find the index of the row with the highest F1 score\n",
    "highest_f1_index = df_metrics['f1_score'].idxmax()\n",
    "\n",
    "# Get the model with the highest F1 score\n",
    "best_model = df_metrics.loc[highest_f1_index]\n",
    "\n",
    "print(f\"Model with the highest F1 score:\\n{best_model}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dcd96b8",
   "metadata": {},
   "source": [
    "<a name=\"7\"></a>\n",
    "## <b> <font color='blue'> 7. Conclusions </font> </b>\n",
    "\n",
    "Fuimos capaces de entrenar diferentes modelos de ML, incluyendo ...\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6401a4b0",
   "metadata": {},
   "source": [
    "<a name=\"8\"></a>\n",
    "## <b> <font color='blue'> 8.  References </font> </b>\n",
    "\n",
    "Esta notebook est√° fuertemente inspirada en ......\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df6a922c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
